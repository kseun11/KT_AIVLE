{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPrxtf3C0sSOC/HfyxhjZn+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium","widgets":{"application/vnd.jupyter.widget-state+json":{"678622291a774621868706807925f4bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_82e0ed9fec5347dfab1e7878f7f1919d","IPY_MODEL_a5718711d27c4061b8eb94a1b13987e9","IPY_MODEL_28b05505e4d54cc0b0fdf14fd6e500fe"],"layout":"IPY_MODEL_600b795ec48a450d8c80b15821ce5698"}},"82e0ed9fec5347dfab1e7878f7f1919d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0856c81f271c49978cc76be399d9b680","placeholder":"​","style":"IPY_MODEL_f677b791a3f542048e890e9a9b510cd8","value":"Downloading: 100%"}},"a5718711d27c4061b8eb94a1b13987e9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf2b57f65f4a418495f9b7bd5bf6446e","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_74234fb75ad8483699cae25bb320efe7","value":231508}},"28b05505e4d54cc0b0fdf14fd6e500fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fbac76f4fa84c0690aa637963c53d7e","placeholder":"​","style":"IPY_MODEL_d3f9511c006f41b8b376de3601a9739c","value":" 232k/232k [00:00&lt;00:00, 2.52MB/s]"}},"600b795ec48a450d8c80b15821ce5698":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0856c81f271c49978cc76be399d9b680":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f677b791a3f542048e890e9a9b510cd8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf2b57f65f4a418495f9b7bd5bf6446e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74234fb75ad8483699cae25bb320efe7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3fbac76f4fa84c0690aa637963c53d7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3f9511c006f41b8b376de3601a9739c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b61716c9396e4b39825598aea1fe9405":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_799d88bd13de42428a8ba851c2bcd592","IPY_MODEL_37f2c8f824f44ebaad3451fa7d9ce9a8","IPY_MODEL_3205f49e518b4361ae0f6ffea8330693"],"layout":"IPY_MODEL_4b22e1b1c60a4fc4bb23c18c638536f0"}},"799d88bd13de42428a8ba851c2bcd592":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_968f6b9f1a674e088bffbaf6c58f05e9","placeholder":"​","style":"IPY_MODEL_931bd7cbbb814faf8ef4f052419ea857","value":"Downloading: 100%"}},"37f2c8f824f44ebaad3451fa7d9ce9a8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e539093b46145f5984a66c4abdf7070","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ffd0f2b81d8240ff921e7bbc18b7052e","value":28}},"3205f49e518b4361ae0f6ffea8330693":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_366710919c5448ee8ca19da204a4715a","placeholder":"​","style":"IPY_MODEL_3e6315f4bf34467bbb5f125d9e6f3601","value":" 28.0/28.0 [00:00&lt;00:00, 1.14kB/s]"}},"4b22e1b1c60a4fc4bb23c18c638536f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"968f6b9f1a674e088bffbaf6c58f05e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"931bd7cbbb814faf8ef4f052419ea857":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e539093b46145f5984a66c4abdf7070":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffd0f2b81d8240ff921e7bbc18b7052e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"366710919c5448ee8ca19da204a4715a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e6315f4bf34467bbb5f125d9e6f3601":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0bb53f83178e4ffdb45878a793d0b9f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0c06932e7bde4a938ce29ef6a2ebae8d","IPY_MODEL_f0fd4d50ab06493f9555ac93656f5016","IPY_MODEL_b9395db556cb4344811205cc0d167b76"],"layout":"IPY_MODEL_06f06978e1024ccabd5815f4fef67939"}},"0c06932e7bde4a938ce29ef6a2ebae8d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f16f9bd9d17b43b6bfae1ac703505061","placeholder":"​","style":"IPY_MODEL_af8a3e0ec46e4c1a8ed8c95fdf5d7ef5","value":"Downloading: 100%"}},"f0fd4d50ab06493f9555ac93656f5016":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b123c04927c412d830533c54bf614f3","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_68e18e3673264233a256c4230242a800","value":570}},"b9395db556cb4344811205cc0d167b76":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c8756fb4e5a402697d180cbf1c3960c","placeholder":"​","style":"IPY_MODEL_07299e002be74b1984b71148f1ed7079","value":" 570/570 [00:00&lt;00:00, 14.0kB/s]"}},"06f06978e1024ccabd5815f4fef67939":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f16f9bd9d17b43b6bfae1ac703505061":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af8a3e0ec46e4c1a8ed8c95fdf5d7ef5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b123c04927c412d830533c54bf614f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68e18e3673264233a256c4230242a800":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6c8756fb4e5a402697d180cbf1c3960c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07299e002be74b1984b71148f1ed7079":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8f9a41b0bfc42c08c192543316ef8d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7413ae81b8fe4dc5ab8571b46c97f9be","IPY_MODEL_4f9c5b85cdd8443cbe1a8dda072a3ea2","IPY_MODEL_70c864a124bb4459b87c1c5e4c621184"],"layout":"IPY_MODEL_023410414efd4ca9a147ea839acdefcb"}},"7413ae81b8fe4dc5ab8571b46c97f9be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f9785e417424a1ba4fee76038c1e14a","placeholder":"​","style":"IPY_MODEL_baa3f9d1b1834808a5f86be2c0b7225c","value":"Downloading: 100%"}},"4f9c5b85cdd8443cbe1a8dda072a3ea2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae92e47551c04a579a31c6c691ae9f9d","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c7389664cbda47d0860687a8d0ca6aa7","value":440473133}},"70c864a124bb4459b87c1c5e4c621184":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3eb9af919ec41e2b2d868a1bac93bc8","placeholder":"​","style":"IPY_MODEL_3996b29b6c5b4a06b1bb008a6300bf5f","value":" 440M/440M [00:06&lt;00:00, 65.2MB/s]"}},"023410414efd4ca9a147ea839acdefcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f9785e417424a1ba4fee76038c1e14a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baa3f9d1b1834808a5f86be2c0b7225c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae92e47551c04a579a31c6c691ae9f9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7389664cbda47d0860687a8d0ca6aa7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c3eb9af919ec41e2b2d868a1bac93bc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3996b29b6c5b4a06b1bb008a6300bf5f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["## Step 0: Connect to Google drive"],"metadata":{"id":"02PKFXgimEks"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l0iQeSzRlywa","executionInfo":{"status":"ok","timestamp":1665219623048,"user_tz":-540,"elapsed":27522,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"19a721fb-8cc7-4893-d34b-f2f50b43768a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","source":["## Step 1: Import modules"],"metadata":{"id":"dUE0iXxTmHYU"}},{"cell_type":"code","source":["import pickle as pc\n","import os\n","import numpy as np\n","import csv\n","import torch\n","\n","# torch 버전 확인\n","print(\"Pytorch Version: \", torch.__version__)\n","\n","# GPU 사용 가능 여부\n","if torch.cuda.is_available():\n","  device = torch.device('cuda')\n","  print(\"There are %d GPU(s) available.\" % torch.cuda.device_count())\n","  print(\"We will use the GPU:\", torch.cuda.get_device_name(0))\n","\n","else:\n","  print(\"No GPU available, using the CPU instead.\")\n","  device = torch.device('cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3gmWft_vmDuA","executionInfo":{"status":"ok","timestamp":1665219909020,"user_tz":-540,"elapsed":2630,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"7f920e6c-11ba-43f6-978a-c07bab610175"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Pytorch Version:  1.12.1+cu113\n","There are 1 GPU(s) available.\n","We will use the GPU: A100-SXM4-40GB\n"]}]},{"cell_type":"markdown","source":["## Step 2: Installing the Hugging Face Library"],"metadata":{"id":"oEVeM0KDmJYS"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JSDFDJWlmL5F","executionInfo":{"status":"ok","timestamp":1665219925393,"user_tz":-540,"elapsed":9042,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"e70cec4e-0b1c-42b2-b0a8-d23c758f86b2"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (5.0.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 67.7 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting huggingface-hub<1.0,>=0.9.0\n","  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 87.7 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.0 tokenizers-0.12.1 transformers-4.22.2\n"]}]},{"cell_type":"markdown","source":["## Step 3: Configure the experiments"],"metadata":{"id":"UI14UUNDmMh5"}},{"cell_type":"markdown","source":["* 모델의 실험을 위해 필요한 파라미터 설정\n","  * Hyperparameter: hidden unit size, vocab size, max length, dropout rate 등\n","  * Argument: file directory 등"],"metadata":{"id":"lxa3jGBY2hgW"}},{"cell_type":"code","source":["train_filename = '/content/gdrive/My Drive/Colab Notebooks/KT_RNN/data/amazon/bert_train_data_all.csv'\n","test_data = '/content/gdrive/My Drive/Colab Notebooks/KT_RNN/data/amazon/bert_balanced_data'\n","test_label = '/content/gdrive/My Drive/Colab Notebooks/KT_RNN/data/amazon/bert_balanced_label'"],"metadata":{"id":"dD3wEZ9zmOIU","executionInfo":{"status":"ok","timestamp":1665220136147,"user_tz":-540,"elapsed":528,"user":{"displayName":"이정연","userId":"10444643468969229023"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Step 4: Load Amazon Review Dataset"],"metadata":{"id":"fuVFHrIPmOvy"}},{"cell_type":"markdown","source":["* load_data: amazon review data에서 [reviewText, label]형태로 데이터를 불러오기"],"metadata":{"id":"xvvgrFYF2vpo"}},{"cell_type":"code","source":["def load_data(filename):\n","  data = list()\n","  label = list()\n","\n","  f = open(filename, 'r', encoding='utf-8')\n","  reader = csv.reader(f)\n","  for idx, line in enumerate(reader):\n","    if idx == 0:\n","      continue\n","\n","    # line[2]에 label 1(긍정), 0(부정) // line[5]에 review text\n","    data.append(line[5])\n","    label.append(int(line[2]))\n","\n","  f.close()\n","\n","  # data와 label 사이즈 일치 여부 확인\n","  assert len(data) == len(label)\n","  return data, label"],"metadata":{"id":"BXadKWQ3mQZt","executionInfo":{"status":"ok","timestamp":1665220889176,"user_tz":-540,"elapsed":498,"user":{"displayName":"이정연","userId":"10444643468969229023"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["train_data, train_label = load_data(train_filename)"],"metadata":{"id":"ZbT49YeO5eFw","executionInfo":{"status":"ok","timestamp":1665220891158,"user_tz":-540,"elapsed":1442,"user":{"displayName":"이정연","userId":"10444643468969229023"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["print(\"Size of train data: {}\".format(len(train_data)))\n","print(\"Size of train label: {}\".format(len(train_label)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"48i8QNgh5kyv","executionInfo":{"status":"ok","timestamp":1665220911580,"user_tz":-540,"elapsed":297,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"a336783f-02ca-4813-e2e2-d5ec7ddf3e28"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of train data: 10727\n","Size of train label: 10727\n"]}]},{"cell_type":"markdown","source":["## Step 5: Tokenization & Input Formatting"],"metadata":{"id":"lnu5d0WDmRFI"}},{"cell_type":"markdown","source":["### Step 5-1: BERT Tokenizer"],"metadata":{"id":"Vo4tpBcumUJC"}},{"cell_type":"markdown","source":["* BERT에서 사용한 tokenizer를 이용. text -> token 단위\n","  * 각 token들을 특정 index로 mapping"],"metadata":{"id":"9gP77uu85vjw"}},{"cell_type":"markdown","source":["* BertTokenizer: punctuation split + wordpiece\n","  * bert-base-uncased: 12 layer, 768 hidden, 12 head, 110M params.\n","  * uncased: 대문자 -> 소문자 후 tokenize."],"metadata":{"id":"DGgbvJXx517_"}},{"cell_type":"code","source":["from transformers import BertTokenizer\n","\n","print(\"Loader BERT tokenizer...\")\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131,"referenced_widgets":["678622291a774621868706807925f4bb","82e0ed9fec5347dfab1e7878f7f1919d","a5718711d27c4061b8eb94a1b13987e9","28b05505e4d54cc0b0fdf14fd6e500fe","600b795ec48a450d8c80b15821ce5698","0856c81f271c49978cc76be399d9b680","f677b791a3f542048e890e9a9b510cd8","cf2b57f65f4a418495f9b7bd5bf6446e","74234fb75ad8483699cae25bb320efe7","3fbac76f4fa84c0690aa637963c53d7e","d3f9511c006f41b8b376de3601a9739c","b61716c9396e4b39825598aea1fe9405","799d88bd13de42428a8ba851c2bcd592","37f2c8f824f44ebaad3451fa7d9ce9a8","3205f49e518b4361ae0f6ffea8330693","4b22e1b1c60a4fc4bb23c18c638536f0","968f6b9f1a674e088bffbaf6c58f05e9","931bd7cbbb814faf8ef4f052419ea857","3e539093b46145f5984a66c4abdf7070","ffd0f2b81d8240ff921e7bbc18b7052e","366710919c5448ee8ca19da204a4715a","3e6315f4bf34467bbb5f125d9e6f3601","0bb53f83178e4ffdb45878a793d0b9f5","0c06932e7bde4a938ce29ef6a2ebae8d","f0fd4d50ab06493f9555ac93656f5016","b9395db556cb4344811205cc0d167b76","06f06978e1024ccabd5815f4fef67939","f16f9bd9d17b43b6bfae1ac703505061","af8a3e0ec46e4c1a8ed8c95fdf5d7ef5","8b123c04927c412d830533c54bf614f3","68e18e3673264233a256c4230242a800","6c8756fb4e5a402697d180cbf1c3960c","07299e002be74b1984b71148f1ed7079"]},"id":"Wz6pW0J_mTSE","executionInfo":{"status":"ok","timestamp":1665221076061,"user_tz":-540,"elapsed":1788,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"bac33b75-1fad-4544-bf07-75fd0c696c57"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Loader BERT tokenizer...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"678622291a774621868706807925f4bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b61716c9396e4b39825598aea1fe9405"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bb53f83178e4ffdb45878a793d0b9f5"}},"metadata":{}}]},{"cell_type":"code","source":["# 하나의 sentence에 대해 BertTokenizer 적용\n","\n","# Print the original sentence.\n","print(\"Original: \", train_data[0])\n","print()\n","\n","# Print the sentence split into tokens.\n","print(\"Tokenized: \", tokenizer.tokenize(train_data[0]))\n","print()\n","\n","# Print the sentence mapped to token ids.\n","print(\"Token IDs: \", tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_data[0])))\n","print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JAtrUyVp6SZ7","executionInfo":{"status":"ok","timestamp":1665221188567,"user_tz":-540,"elapsed":368,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"b8e4b24d-55d6-48de-c6b0-ed2baad4dc8c"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  I never thought that I would find the right moisturizer for my skin. I have combination skin with large pores that get gunked up if I neglect them and I ve struggled for some time to find a product that would provide sufficient moisture without breaking me out or turning my face into an oil-slick. This is truly a holy grail moisturizer for me and has a nice face feel and natural herbal scent. Will definitely repurchase!  I m a 30 something multi-ethnic muxer and a recent convert to korean beauty. This is my new routine and my skin has never felt or looked bettter!  1) Banila Co Clean It Zero Reservatrol 2) Neogen Green Tea Real Fresh Foam Cleanser 3) MISSHA Time Revolution First Treatment Essence (Morning) or MISSHA Time Revolution Night Repair New Science Ampoule (Night) 4) Cosrx Oil-Free Ultra-Moisturizing Lotion (Morning and ever OTHER night) or Cosrx Ultimate Nourishing Rice Overnight Mask\n","\n","Tokenized:  ['i', 'never', 'thought', 'that', 'i', 'would', 'find', 'the', 'right', 'moist', '##uri', '##zer', 'for', 'my', 'skin', '.', 'i', 'have', 'combination', 'skin', 'with', 'large', 'por', '##es', 'that', 'get', 'gun', '##ked', 'up', 'if', 'i', 'neglect', 'them', 'and', 'i', 've', 'struggled', 'for', 'some', 'time', 'to', 'find', 'a', 'product', 'that', 'would', 'provide', 'sufficient', 'moisture', 'without', 'breaking', 'me', 'out', 'or', 'turning', 'my', 'face', 'into', 'an', 'oil', '-', 'slick', '.', 'this', 'is', 'truly', 'a', 'holy', 'gr', '##ail', 'moist', '##uri', '##zer', 'for', 'me', 'and', 'has', 'a', 'nice', 'face', 'feel', 'and', 'natural', 'herbal', 'scent', '.', 'will', 'definitely', 'rep', '##ur', '##chase', '!', 'i', 'm', 'a', '30', 'something', 'multi', '-', 'ethnic', 'mu', '##x', '##er', 'and', 'a', 'recent', 'convert', 'to', 'korean', 'beauty', '.', 'this', 'is', 'my', 'new', 'routine', 'and', 'my', 'skin', 'has', 'never', 'felt', 'or', 'looked', 'bet', '##tter', '!', '1', ')', 'ban', '##ila', 'co', 'clean', 'it', 'zero', 'res', '##er', '##vat', '##rol', '2', ')', 'neo', '##gen', 'green', 'tea', 'real', 'fresh', 'foam', 'clean', '##ser', '3', ')', 'miss', '##ha', 'time', 'revolution', 'first', 'treatment', 'essence', '(', 'morning', ')', 'or', 'miss', '##ha', 'time', 'revolution', 'night', 'repair', 'new', 'science', 'amp', '##ou', '##le', '(', 'night', ')', '4', ')', 'co', '##sr', '##x', 'oil', '-', 'free', 'ultra', '-', 'moist', '##uri', '##zing', 'lot', '##ion', '(', 'morning', 'and', 'ever', 'other', 'night', ')', 'or', 'co', '##sr', '##x', 'ultimate', 'no', '##uri', '##shing', 'rice', 'overnight', 'mask']\n","\n","Token IDs:  [1045, 2196, 2245, 2008, 1045, 2052, 2424, 1996, 2157, 11052, 9496, 6290, 2005, 2026, 3096, 1012, 1045, 2031, 5257, 3096, 2007, 2312, 18499, 2229, 2008, 2131, 3282, 8126, 2039, 2065, 1045, 19046, 2068, 1998, 1045, 2310, 6915, 2005, 2070, 2051, 2000, 2424, 1037, 4031, 2008, 2052, 3073, 7182, 14098, 2302, 4911, 2033, 2041, 2030, 3810, 2026, 2227, 2046, 2019, 3514, 1011, 13554, 1012, 2023, 2003, 5621, 1037, 4151, 24665, 12502, 11052, 9496, 6290, 2005, 2033, 1998, 2038, 1037, 3835, 2227, 2514, 1998, 3019, 27849, 6518, 1012, 2097, 5791, 16360, 3126, 26300, 999, 1045, 1049, 1037, 2382, 2242, 4800, 1011, 5636, 14163, 2595, 2121, 1998, 1037, 3522, 10463, 2000, 4759, 5053, 1012, 2023, 2003, 2026, 2047, 9410, 1998, 2026, 3096, 2038, 2196, 2371, 2030, 2246, 6655, 12079, 999, 1015, 1007, 7221, 11733, 2522, 4550, 2009, 5717, 24501, 2121, 22879, 13153, 1016, 1007, 9253, 6914, 2665, 5572, 2613, 4840, 17952, 4550, 8043, 1017, 1007, 3335, 3270, 2051, 4329, 2034, 3949, 11305, 1006, 2851, 1007, 2030, 3335, 3270, 2051, 4329, 2305, 7192, 2047, 2671, 23713, 7140, 2571, 1006, 2305, 1007, 1018, 1007, 2522, 21338, 2595, 3514, 1011, 2489, 11087, 1011, 11052, 9496, 6774, 2843, 3258, 1006, 2851, 1998, 2412, 2060, 2305, 1007, 2030, 2522, 21338, 2595, 7209, 2053, 9496, 12227, 5785, 11585, 7308]\n","\n"]}]},{"cell_type":"markdown","source":["### Step 5-2: Required Formatting\n","\n","  * Input을 Formatting (입력 3층 만들기)\n","    * 각 문장의 처음과 끝에 special token 더하기\n","      * [SEP]: 모든 문장 뒤에 추가\n","      * [CLS]: 문장의 앞에 추가\n","    * 각 문장을 max_length만큼 자르고 padding token 채우기\n","      * 모든 문장들은 하나의 고정된 길이를 지녀야 함\n","      * max_length보다 긴 문장의 경우 잘라줌\n","      * max_length보다 작은 경우는 남은 부분을 [PAD] 로 채워줌\n","        * [PAD]: BERT 사전에서 index0에 해당\n","        * 여기서 max_len은 512\n","    * 각 문장에서 padding token과 실제 token을 구분하기 위한 attention masking 적용\n","      * 토큰이 실제 값인지, [PAD]인지를 구분하는 binary tensor\n","      * 어텐션 연산을 할 때, 불필요하게 패딩 토큰에 대해 어텐션을 하지 않도록 구분\n","      * 1은 실제 단어. 마스킹을 하지 않음.\n","      * 0은 패딩 토큰. 마스킹을 함."],"metadata":{"id":"dIZ7WqIUmW-X"}},{"cell_type":"markdown","source":["* Sentences to IDs\n","\n","  * 위 과정들을 한꺼번에 처리\n","  * word piece들은 내부적으로 할당된 ID가 있음"],"metadata":{"id":"RfFV39nGmg1M"}},{"cell_type":"code","source":["# Tokenize -> map the tokens & word IDs.\n","input_ids = []\n","\n","# For every sentence\n","for sent in train_data:\n","  # (1) Tokenize the sentence.\n","  # (2) [CLS] token to the start\n","  # (3) [SEP] token to the end\n","  encoded_sent = tokenizer.encode(sent, add_special_tokens=True, max_length=64)\n","\n","  # Add the encoded sentence to the list\n","  input_ids.append(encoded_sent)\n","\n","# Print train data[0]\n","print(\"Original: \", train_data[0])\n","print()\n","print(\"Token IDs: \", input_ids[0])\n","\n","# Print special tokens and tokenized sentence\n","print(\"\\n[CLS] token: {:}, ID: {:}\".format(tokenizer.cls_token, tokenizer.cls_token_id))\n","print(\"\\n[PAD] token: {:}, ID: {:}\".format(tokenizer.pad_token, tokenizer.pad_token_id))\n","print(\"\\n[SEP] token: {:}, ID: {:}\".format(tokenizer.sep_token, tokenizer.sep_token_id))\n","print(\"\\nTokenized: \", tokenizer.convert_ids_to_tokens(input_ids[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SPmEEtECmZVG","executionInfo":{"status":"ok","timestamp":1665221742308,"user_tz":-540,"elapsed":11561,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"60f0b1e4-20dc-406c-9c85-7c717ecf3d1a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["Original:  I never thought that I would find the right moisturizer for my skin. I have combination skin with large pores that get gunked up if I neglect them and I ve struggled for some time to find a product that would provide sufficient moisture without breaking me out or turning my face into an oil-slick. This is truly a holy grail moisturizer for me and has a nice face feel and natural herbal scent. Will definitely repurchase!  I m a 30 something multi-ethnic muxer and a recent convert to korean beauty. This is my new routine and my skin has never felt or looked bettter!  1) Banila Co Clean It Zero Reservatrol 2) Neogen Green Tea Real Fresh Foam Cleanser 3) MISSHA Time Revolution First Treatment Essence (Morning) or MISSHA Time Revolution Night Repair New Science Ampoule (Night) 4) Cosrx Oil-Free Ultra-Moisturizing Lotion (Morning and ever OTHER night) or Cosrx Ultimate Nourishing Rice Overnight Mask\n","\n","Token IDs:  [101, 1045, 2196, 2245, 2008, 1045, 2052, 2424, 1996, 2157, 11052, 9496, 6290, 2005, 2026, 3096, 1012, 1045, 2031, 5257, 3096, 2007, 2312, 18499, 2229, 2008, 2131, 3282, 8126, 2039, 2065, 1045, 19046, 2068, 1998, 1045, 2310, 6915, 2005, 2070, 2051, 2000, 2424, 1037, 4031, 2008, 2052, 3073, 7182, 14098, 2302, 4911, 2033, 2041, 2030, 3810, 2026, 2227, 2046, 2019, 3514, 1011, 13554, 102]\n","\n","[CLS] token: [CLS], ID: 101\n","\n","[PAD] token: [PAD], ID: 0\n","\n","[SEP] token: [SEP], ID: 102\n","\n","Tokenized:  ['[CLS]', 'i', 'never', 'thought', 'that', 'i', 'would', 'find', 'the', 'right', 'moist', '##uri', '##zer', 'for', 'my', 'skin', '.', 'i', 'have', 'combination', 'skin', 'with', 'large', 'por', '##es', 'that', 'get', 'gun', '##ked', 'up', 'if', 'i', 'neglect', 'them', 'and', 'i', 've', 'struggled', 'for', 'some', 'time', 'to', 'find', 'a', 'product', 'that', 'would', 'provide', 'sufficient', 'moisture', 'without', 'breaking', 'me', 'out', 'or', 'turning', 'my', 'face', 'into', 'an', 'oil', '-', 'slick', '[SEP]']\n"]}]},{"cell_type":"code","source":["len(tokenizer.convert_ids_to_tokens(input_ids[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GQD6zk0s89UR","executionInfo":{"status":"ok","timestamp":1665221924719,"user_tz":-540,"elapsed":321,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"7783f768-11e1-4c87-d71b-da3b6ca9b749"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["64"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["* Padding & Truncating\n","\n","  * tf.keras.preprocessing.sequence.pad_sequences\n","    * max_len만큼 padding을 진행"],"metadata":{"id":"lrZc16t3miqC"}},{"cell_type":"code","source":["# 입력으로 들어오는 문장의 최대 길이를 지정\n","print(\"Max length: \", max([len(each) for each in input_ids]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4UgTluYVmkfK","executionInfo":{"status":"ok","timestamp":1665222032051,"user_tz":-540,"elapsed":353,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"96b3a68e-575e-4c03-9f8f-2bf233601635"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Max length:  64\n"]}]},{"cell_type":"code","source":["len(input_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GexElMiM97tf","executionInfo":{"status":"ok","timestamp":1665222038163,"user_tz":-540,"elapsed":293,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"5f288df6-a05d-4e7f-f5d9-958952fd364c"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10727"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["import tensorflow as tf\n","print(\"Tensorflow version: {}\".format(tf.__version__))\n","\n","MAXLEN = 64\n","\n","input_ids = tf.keras.preprocessing.sequence.pad_sequences(input_ids, maxlen=MAXLEN,\n","                                                         dtype='long', value=0,\n","                                                         truncating='post', padding='post')\n","\n","print(\"\\nPadding is done.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2xURONBN98FB","executionInfo":{"status":"ok","timestamp":1665222180826,"user_tz":-540,"elapsed":386,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"f030eee3-944f-4552-e932-704d5b7b287b"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensorflow version: 2.8.2\n","\n","Padding is done.\n"]}]},{"cell_type":"code","source":["# 64로 잘 됨\n","len(input_ids[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lXYWHjJp-hFI","executionInfo":{"status":"ok","timestamp":1665222195261,"user_tz":-540,"elapsed":302,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"727e6bc2-4d64-4fda-d221-f792ea03f1cb"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["64"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["len(input_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aJpVvSEfA4m6","executionInfo":{"status":"ok","timestamp":1665222810397,"user_tz":-540,"elapsed":325,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"60802af8-f1e6-4ff6-ea3c-89c2c9e7a5fe"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10727"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["* Attention Masks"],"metadata":{"id":"nWeXUNJWmlHv"}},{"cell_type":"code","source":["# Create attention masks\n","attention_masks = [] # 각 문장에 대한 attention mask 리스트를 저장\n","\n","# attention mask 생성\n","for sent in input_ids: # token id가 10727개 들어있음\n","  # Create the attention mask.\n","  att_mask = [int(token_id > 0) for token_id in sent]\n","\n","  # Store the attention mask for this sentence.\n","  attention_masks.append(att_mask)\n","print(\"\\nAttention masking is done.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nolGZNfBmmCR","executionInfo":{"status":"ok","timestamp":1665222886227,"user_tz":-540,"elapsed":801,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"f4ee1a02-a747-4b6f-a73f-ca2d84c18010"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Attention masking is done.\n"]}]},{"cell_type":"markdown","source":["* Training & Validation Split"],"metadata":{"id":"sKkTgheemm6Z"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# data, labels\n","train_inputs, valid_inputs, train_labels, valid_labels = train_test_split(input_ids, train_label, random_state=2022, test_size=0.1)\n","\n","# masks\n","train_masks, valid_masks, _, _ = train_test_split(attention_masks, train_label, random_state=2022, test_size=0.1)\n","\n","# 확인\n","print(train_inputs[:1])\n","print(train_masks[:1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F7am1tk_mo0w","executionInfo":{"status":"ok","timestamp":1665223035390,"user_tz":-540,"elapsed":302,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"d44fe8ea-a235-4068-98fc-368a60965bdd"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["[[  101  1045  1521  1049  1037  3486  1061  3217  4004  2450  2007  4318\n","   3096  1998  1045  1521  2310  2042  2478  2023 11052  9496  6290  2005\n","   1016  2706  1006  7237  2058  2013 11382 11106  4877  4415  6149  3512\n","   7861 23316  1007  1012  2009  8440  1521  1056  3714  2033  2041  1998\n","   1045  1521  2310  2042  2893 25327  8491 18856  8649  5999 18499  2229\n","   1012  1045  2572   102]]\n","[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"]}]},{"cell_type":"markdown","source":["* Converting to PyTorch Data Types"],"metadata":{"id":"869VUBAWmphQ"}},{"cell_type":"code","source":["# torch.tensor(data) -> tensor\n","train_inputs = torch.tensor(train_inputs)\n","valid_inputs = torch.tensor(valid_inputs)\n","\n","train_labels = torch.tensor(train_labels)\n","valid_labels = torch.tensor(valid_labels)\n","\n","train_masks = torch.tensor(train_masks)\n","valid_masks = torch.tensor(valid_masks)"],"metadata":{"id":"UL8dGu-GmrLe","executionInfo":{"status":"ok","timestamp":1665223158512,"user_tz":-540,"elapsed":405,"user":{"displayName":"이정연","userId":"10444643468969229023"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["* DataLoader 이용. iterator를 생성.\n","  * TensorDataset: tensor를 입력받아 dataset 형태로 변환\n","  * RandomSampler: 입력 dataset에 element들의 index를 무작위로 샘플링\n","  * SequentialSampler: 입력 dataset에 element들의 index를 순차적으로 샘플링\n","  * DataLoader: dataset과 sampler를 이용하여 주어진 dataset에 대해 batch size만큼 데이터를 반환"],"metadata":{"id":"B1aKKV9zCRGx"}},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","batch_size = 32\n","\n","# train dataloader\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# valid dataloader\n","valid_data = TensorDataset(valid_inputs, valid_masks, valid_labels)\n","valid_sampler = SequentialSampler(valid_data)\n","valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size)"],"metadata":{"id":"53FlShAoCPc7","executionInfo":{"status":"ok","timestamp":1665223636384,"user_tz":-540,"elapsed":308,"user":{"displayName":"이정연","userId":"10444643468969229023"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["## Step 6: Train our classification model"],"metadata":{"id":"ivs4T7T7mr1c"}},{"cell_type":"markdown","source":["### Step 6-1: BertForSequenceClassification\n","\n","* pre-trained BERT 모델 위에 single linear layer 하나가 더해진 모델을 불러오기\n","\n","* 해당 모델을 우리가 원하는 task에 맞게 end-to-end 방식으로 fine-tuning을 진행할 수 있음\n","\n","* (bert): Embedding 정보\n","* (encoder): 인코더 정보"],"metadata":{"id":"3fvW_9i6mu3V"}},{"cell_type":"code","source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n","                                                      num_labels = 2,\n","                                                      output_attentions = False,\n","                                                      output_hidden_states = False)\n","\n","model.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f8f9a41b0bfc42c08c192543316ef8d2","7413ae81b8fe4dc5ab8571b46c97f9be","4f9c5b85cdd8443cbe1a8dda072a3ea2","70c864a124bb4459b87c1c5e4c621184","023410414efd4ca9a147ea839acdefcb","2f9785e417424a1ba4fee76038c1e14a","baa3f9d1b1834808a5f86be2c0b7225c","ae92e47551c04a579a31c6c691ae9f9d","c7389664cbda47d0860687a8d0ca6aa7","c3eb9af919ec41e2b2d868a1bac93bc8","3996b29b6c5b4a06b1bb008a6300bf5f"]},"id":"4Nz7n7Zkmt9E","executionInfo":{"status":"ok","timestamp":1665223866448,"user_tz":-540,"elapsed":15553,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"f4ef24fc-5316-4971-ce44-7a8ab5bcf106"},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8f9a41b0bfc42c08c192543316ef8d2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# Get all of the model's parameters as a list of tuples\n","params = list(model.named_parameters())\n","\n","print(\"The BERT model has {:} different named parameters.\\n\".format(len(params)))\n","print(\"=== Embedding Layer ===\\n\")\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print(\"\\n==== First Transformer ====\\n\")\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print(\"\\n==== Output Layer====\\n\")\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hao9hmgbFEB8","executionInfo":{"status":"ok","timestamp":1665223932100,"user_tz":-540,"elapsed":339,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"5db8261d-2c85-49f4-b0e2-4e3fc8dc97fb"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["The BERT model has 201 different named parameters.\n","\n","=== Embedding Layer ===\n","\n","bert.embeddings.word_embeddings.weight                  (30522, 768)\n","bert.embeddings.position_embeddings.weight                (512, 768)\n","bert.embeddings.token_type_embeddings.weight                (2, 768)\n","bert.embeddings.LayerNorm.weight                              (768,)\n","bert.embeddings.LayerNorm.bias                                (768,)\n","\n","==== First Transformer ====\n","\n","bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.query.bias                (768,)\n","bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n","bert.encoder.layer.0.attention.self.key.bias                  (768,)\n","bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.value.bias                (768,)\n","bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n","bert.encoder.layer.0.attention.output.dense.bias              (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n","bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n","bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n","bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n","bert.encoder.layer.0.output.dense.bias                        (768,)\n","bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n","bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n","\n","==== Output Layer====\n","\n","bert.pooler.dense.weight                                  (768, 768)\n","bert.pooler.dense.bias                                        (768,)\n","classifier.weight                                           (2, 768)\n","classifier.bias                                                 (2,)\n"]}]},{"cell_type":"markdown","source":["### Step 6-2: Optimizer & Learning Rate Scheduler\n","\n","- learning rate scheduler: learning rate를 조절"],"metadata":{"id":"qpv4dyp9mzUA"}},{"cell_type":"code","source":["optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZWZSmb84m2fF","executionInfo":{"status":"ok","timestamp":1665224035232,"user_tz":-540,"elapsed":292,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"6d0871af-c991-476d-f8e9-640e75333e45"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["from transformers import get_linear_schedule_with_warmup\n","\n","epochs = 4\n","\n","# Total number of training steps = number of batches * number of epochs\n","print(\"number of batches:\", len(train_dataloader))\n","total_steps = len(train_dataloader) * epochs\n","\n","print(\"total_steps:\", total_steps)\n","\n","# Create the learning rate scheduler\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QQVJ-sZ_FTv0","executionInfo":{"status":"ok","timestamp":1665224145954,"user_tz":-540,"elapsed":314,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"af01a19d-dacf-4935-a332-743e45d2e798"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["number of batches: 302\n","total_steps: 1208\n"]}]},{"cell_type":"markdown","source":["### Step 6-3: Training Loop\n","\n","* DataLoader를 통해 data와 label을 batch 단위로 가져오기\n","* Forward pass: data와 label을 모델에 입력으로 주기\n","* Backward pass:\n","  * minibatch gradient 계산 (backpropagation)\n","  * 모델의 파라미터 업데이트 (optimization)"],"metadata":{"id":"379JEu82m3Eu"}},{"cell_type":"code","source":["# Function to calculate the accuracy of predictions vs labels\n","\n","def flat_accuracy(preds, labels):\n","  # argmax: 해당 axis의 값 중에서 가장 큰 값의 인덱스를 반환\n","  pred_flat = np.argmax(preds, axis=1).flatten()\n","  labels_flat = labels.flatten()\n","  return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"klXCAVORm4gb","executionInfo":{"status":"ok","timestamp":1665224387351,"user_tz":-540,"elapsed":308,"user":{"displayName":"이정연","userId":"10444643468969229023"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["import time\n","import datetime\n","\n","# Take a time in seconds and returns a string hh:mm:ss\n","def format_time(elapsed):\n","  # Round to the nearest second\n","  elapsed_rounded = int(round(elapsed))\n","\n","  # Format as hh:mm:ss\n","  return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"cBommLJeG60Q","executionInfo":{"status":"ok","timestamp":1665224458687,"user_tz":-540,"elapsed":304,"user":{"displayName":"이정연","userId":"10444643468969229023"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","# Set the seed value\n","def set_seed(seed_val):\n","  random.seed(seed_val)\n","  np.random.seed(seed_val)\n","  torch.manual_seed(seed_val)\n","  torch.cuda.manual_seed_all(seed_val)"],"metadata":{"id":"c8arCPg6HL3f","executionInfo":{"status":"ok","timestamp":1665224494041,"user_tz":-540,"elapsed":425,"user":{"displayName":"이정연","userId":"10444643468969229023"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["seed_val = 42\n","set_seed(seed_val)\n","\n","# Store the average loss after each epoch\n","loss_values = []\n","\n","# Epoch\n","for epoch in range(0, epochs):\n","    # ========================================\n","    #               Training\n","    # ========================================\n","\n","    # Perform one full pass over the training set\n","    print(\"\")\n","    print(\"======= Epoch {:} / {:} =======\".format(epoch + 1, epochs))\n","    print(\"Training...\")\n","\n","    # Measure how long the epoch takes\n","    t0 = time.time()\n","\n","    # Reset the total loss\n","    total_loss = 0.\n","\n","    # Put the model into training mode\n","    model.train()\n","\n","    # For each batch of training data\n","    for step, batch in enumerate(train_dataloader):\n","      # Progress update every 40 batches\n","      if step % 40 == 0 and not step == 0:\n","\n","        # Calculate elapsed time in minutes\n","        elapsed = format_time(time.time() - t0)\n","\n","        # Report progress\n","        print(\"Batch {:>5,} of {:>5,}. Elapsed: {:}.\".format(step, len(train_dataloader), elapsed))\n","\n","      # Unpack this training batch from our dataloader\n","      # [0] : input ids\n","      # [1] : attention masks\n","      # [2] : labels\n","      b_input_ids = batch[0].to(device)\n","      b_input_mask = batch[1].to(device)\n","      b_labels = batch[2].to(device)\n","\n","      # Clear gradients before performing a backward pass\n","      model.zero_grad()\n","\n","      # Forward Pass\n","      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","\n","      # model returns a tuple\n","      # need to pull the loss value out of the tuple\n","      loss = outputs[0]\n","\n","      # Accumulate the training loss\n","      total_loss += loss.item()\n","\n","      # Backward Pass\n","      loss.backward()\n","\n","      # Clip the norm of the gradients to 1.0\n","      # Prevent the exploding gradients\n","      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","      # Update parameters and take a step\n","      optimizer.step()\n","\n","      # Update the lr\n","      scheduler.step()\n","\n","    # Calculate the average loss over the train data\n","    avg_train_loss = total_loss / len(train_dataloader)\n","\n","    # Store the loss value for plotting the learning curve\n","    loss_values.append(avg_train_loss)\n","\n","    print(\"\")\n","    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"Training epoch took: {:}\".format(format_time(time.time() - t0)))\n","\n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    # measure our performance on the valid set\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # model in evaluation mode\n","    model.eval()\n","\n","    # Tracking variables\n","    eval_loss, eval_acc = 0., 0.\n","\n","    # Evaluate data for one epoch\n","    for valid_step, batch in enumerate(valid_dataloader):\n","      # Add batch to GPU\n","      batch = tuple(t.to(device) for t in batch)\n","\n","      # Unpack the inputs from our dataloader\n","      b_input_ids, b_input_mask, b_labels = batch\n","\n","      with torch.no_grad():\n","        # Forward pass, calculate logit pred\n","        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","\n","      # Get the logits output by the model\n","      logits = outputs[0]\n","\n","      # Move logits and labels to CPU\n","      logits = logits.detach().cpu().numpy()\n","      label_ids = b_labels.to('cpu').numpy()\n","\n","      # Calculate the accuracy for this batch of test sentences\n","      tmp_eval_acc = flat_accuracy(logits, label_ids)\n","\n","      # Accumulate the total accuracy\n","      eval_acc += tmp_eval_acc\n","\n","    # Report the final accuracy for validation\n","    print(\"Accuracy: {0:.2f}\".format(eval_acc / (valid_step + 1)))\n","    print(\"Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NojI-XOsHVD2","executionInfo":{"status":"ok","timestamp":1665225595254,"user_tz":-540,"elapsed":119539,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"46a4ddb9-e9a0-4a62-ca13-ca795ecb50dc"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======= Epoch 1 / 4 =======\n","Training...\n","Batch    40 of   302. Elapsed: 0:00:07.\n","Batch    80 of   302. Elapsed: 0:00:10.\n","Batch   120 of   302. Elapsed: 0:00:14.\n","Batch   160 of   302. Elapsed: 0:00:18.\n","Batch   200 of   302. Elapsed: 0:00:22.\n","Batch   240 of   302. Elapsed: 0:00:25.\n","Batch   280 of   302. Elapsed: 0:00:29.\n","\n","Average training loss: 0.18\n","Training epoch took: 0:00:31\n","\n","Running Validation...\n","Accuracy: 0.97\n","Validation took: 0:00:01\n","\n","======= Epoch 2 / 4 =======\n","Training...\n","Batch    40 of   302. Elapsed: 0:00:04.\n","Batch    80 of   302. Elapsed: 0:00:07.\n","Batch   120 of   302. Elapsed: 0:00:11.\n","Batch   160 of   302. Elapsed: 0:00:15.\n","Batch   200 of   302. Elapsed: 0:00:19.\n","Batch   240 of   302. Elapsed: 0:00:22.\n","Batch   280 of   302. Elapsed: 0:00:26.\n","\n","Average training loss: 0.06\n","Training epoch took: 0:00:28\n","\n","Running Validation...\n","Accuracy: 0.97\n","Validation took: 0:00:01\n","\n","======= Epoch 3 / 4 =======\n","Training...\n","Batch    40 of   302. Elapsed: 0:00:04.\n","Batch    80 of   302. Elapsed: 0:00:07.\n","Batch   120 of   302. Elapsed: 0:00:11.\n","Batch   160 of   302. Elapsed: 0:00:15.\n","Batch   200 of   302. Elapsed: 0:00:19.\n","Batch   240 of   302. Elapsed: 0:00:22.\n","Batch   280 of   302. Elapsed: 0:00:26.\n","\n","Average training loss: 0.03\n","Training epoch took: 0:00:28\n","\n","Running Validation...\n","Accuracy: 0.97\n","Validation took: 0:00:01\n","\n","======= Epoch 4 / 4 =======\n","Training...\n","Batch    40 of   302. Elapsed: 0:00:04.\n","Batch    80 of   302. Elapsed: 0:00:07.\n","Batch   120 of   302. Elapsed: 0:00:11.\n","Batch   160 of   302. Elapsed: 0:00:15.\n","Batch   200 of   302. Elapsed: 0:00:19.\n","Batch   240 of   302. Elapsed: 0:00:22.\n","Batch   280 of   302. Elapsed: 0:00:26.\n","\n","Average training loss: 0.01\n","Training epoch took: 0:00:28\n","\n","Running Validation...\n","Accuracy: 0.97\n","Validation took: 0:00:01\n","\n","Training complete!\n"]}]},{"cell_type":"code","source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Use plot styling from seaborn\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size\n","sns.set(font_scale=1.5)\n","plt.rcParams['figure.figsize'] = (12, 6)\n","\n","# Plot the learning curve\n","plt.plot(loss_values, 'b-o')\n","\n","# Label the plot\n","plt.title(\"Training loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"CB0xp4LzLGQf","executionInfo":{"status":"ok","timestamp":1665225614841,"user_tz":-540,"elapsed":514,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"d37d35fd-64ad-4cc3-9497-4198a51b2278"},"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 864x432 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## Step 7: Performance on Test set"],"metadata":{"id":"6KaX8qaam53O"}},{"cell_type":"markdown","source":["### Step 7-1: Load Amazon Review Test Dataset"],"metadata":{"id":"pgxUUohgm8Ta"}},{"cell_type":"code","source":["# pickle 모듈로 테스트 파일을 load\n","with open(test_data, 'rb') as f:\n","  test_data = pc.load(f)\n","with open(test_label, 'rb') as f:\n","  test_label = pc.load(f)\n","\n","\n","print(\"Size of test data: {}\".format(len(test_data)))\n","print(\"Size of test label: {}\".format(len(test_label)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2aJ1Tfptm_B0","executionInfo":{"status":"ok","timestamp":1665225692895,"user_tz":-540,"elapsed":1307,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"e50e05a2-14cc-49d8-9fce-72bb2643d5fc"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of test data: 174\n","Size of test label: 174\n"]}]},{"cell_type":"markdown","source":["### Step 7-2: Tokenization & Input Formatting\n","\n","* BERT 모델의 입력 format에 맞게 test data를 변환"],"metadata":{"id":"nO9DkCfpm_dP"}},{"cell_type":"code","source":["input_ids = []\n","\n","for sent in test_data:\n","  encoded_sent = tokenizer.encode(sent, add_special_tokens=True)\n","  input_ids.append(encoded_sent)\n","\n","# Pad input tokens\n","input_ids = tf.keras.preprocessing.sequence.pad_sequences(input_ids, maxlen=MAXLEN,\n","                                                          dtype='long', truncating='post', padding='post')\n","\n","# attention masks\n","attention_masks = []\n","\n","for sent in input_ids:\n","  att_mask = [int(token_id > 0) for token_id in sent]\n","  attention_masks.append(att_mask)\n","\n","# Convert to tensors\n","prediction_inputs = torch.tensor(input_ids)\n","prediction_masks = torch.tensor(attention_masks)\n","prediction_labels = torch.tensor(test_label)\n","\n","batch_size = 32\n","\n","# DataLoader\n","prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n","prediction_sampler = SequentialSampler(prediction_data) \n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"metadata":{"id":"dP0fxvd3nBx-","executionInfo":{"status":"ok","timestamp":1665225947221,"user_tz":-540,"elapsed":297,"user":{"displayName":"이정연","userId":"10444643468969229023"}}},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":["### Step 7-3: Evaluate on Test Set"],"metadata":{"id":"R8XBqiS5nChR"}},{"cell_type":"code","source":["# Prediction on test set\n","print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n","\n","# Put model in evaluation mode\n","model.eval()\n","\n","# Tracking variables \n","predictions, true_labels = [], []\n","\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  # Unpack the inputs from our dataloader (batch에서 데이터 추출)\n","  b_input_ids, b_input_mask, b_labels = batch\n","  \n","  # Telling the model not to compute or store gradients, saving memory and \n","  # speeding up prediction\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","      \n","  logits = outputs[0]\n","\n","  # Move logits and labels to CPU\n","\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","\n","  # Store predictions and true labels\n","  # predictions : 예측값 array\n","  # true_labels : 정답값 array\n","  # logits array의 값들 중 가장 큰 값의 index를 반환\n","  # when axis = 1, argmax identifies the maximum value for every row. \n","  predictions.extend(np.argmax(logits, axis=1).flatten()) # [0, 1, 1, 0, ...]\n","  true_labels.extend(label_ids.flatten()) # [0, 1, 0, 0, ...]\n","\n","print('DONE.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KJ0Pp9pCnEgy","executionInfo":{"status":"ok","timestamp":1665225973910,"user_tz":-540,"elapsed":350,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"5e7b2387-6437-42d0-af4a-d6a3e52f94e9"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting labels for 174 test sentences...\n","DONE.\n"]}]},{"cell_type":"code","source":["# accuracy, precision, recall, f1 score 성능 확인\n","from sklearn.metrics import classification_report\n","    \n","target_names = ['negative', 'positive']\n","\n","print(classification_report(true_labels, predictions, digits=4, target_names=target_names))"],"metadata":{"id":"KjLruVVlM91R","executionInfo":{"status":"ok","timestamp":1665225982312,"user_tz":-540,"elapsed":369,"user":{"displayName":"이정연","userId":"10444643468969229023"}},"outputId":"8bdde767-d19d-4a58-e73b-7652d0ada155","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","    negative     0.9467    0.8161    0.8765        87\n","    positive     0.8384    0.9540    0.8925        87\n","\n","    accuracy                         0.8851       174\n","   macro avg     0.8925    0.8851    0.8845       174\n","weighted avg     0.8925    0.8851    0.8845       174\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"QDCGDb8IM_4b"},"execution_count":null,"outputs":[]}]}